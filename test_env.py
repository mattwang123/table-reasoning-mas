import sys

def check_package(name, import_name=None):
    if import_name is None:
        import_name = name
    try:
        module = __import__(import_name)
        version = getattr(module, '__version__', 'Unknown')
        print(f"   âœ… {name}: {version}")
        return True
    except ImportError:
        print(f"   âŒ {name}: MISSING!")
        return False

print("ğŸ” Complete Environment Verification")
print("=" * 50)

# Critical packages for data collection
print("\nğŸ“Š Data Collection Packages:")
data_packages = [
    ('PyTorch', 'torch'),
    ('Transformers', 'transformers'), 
    ('vLLM', 'vllm'),  # CRITICAL!
    ('Datasets', 'datasets'),
    ('NumPy', 'numpy'),
    ('Pandas', 'pandas'),
    ('PyYAML', 'yaml'),
]

data_ok = all(check_package(name, imp) for name, imp in data_packages)

# Critical packages for training
print("\nğŸ¯ Training Packages:")
train_packages = [
    ('TRL', 'trl'),
    ('PEFT', 'peft'),
    ('Accelerate', 'accelerate'),
    ('DeepSpeed', 'deepspeed'),
    ('Wandb', 'wandb'),
]

train_ok = all(check_package(name, imp) for name, imp in train_packages)

# GPU check
print("\nğŸš€ GPU Setup:")
try:
    import torch
    if torch.cuda.is_available():
        print(f"   âœ… CUDA: {torch.version.cuda}")
        print(f"   âœ… GPUs: {torch.cuda.device_count()}")
        for i in range(torch.cuda.device_count()):
            props = torch.cuda.get_device_properties(i)
            print(f"      GPU {i}: {props.name} ({props.total_memory//1e9:.0f}GB)")
    else:
        print("   âŒ CUDA not available!")
except:
    print("   âŒ Cannot check CUDA")

print(f"\nğŸ“‹ Summary:")
print(f"   Data Collection Ready: {'âœ…' if data_ok else 'âŒ'}")
print(f"   Training Ready: {'âœ…' if train_ok else 'âŒ'}")

if data_ok and train_ok:
    print("\nğŸ‰ Complete pipeline ready!")
    print("   âœ… Data collection with vLLM")
    print("   âœ… Data processing") 
    print("   âœ… GRPO training with TRL")
else:
    print("\nâŒ Setup incomplete - install missing packages")
    sys.exit(1)